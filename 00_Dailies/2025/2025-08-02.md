-  minplus 缺少一个最后加权完之后的 sparsity，其实相当于看最后保留了哪个tau
- 其实不管K取了多少，可能针对当前任务最优的稀疏性就是确定的， 看一下 k100，k500他们最后学到向量进行分析
- 目前实验的takeaway
	- truncation 还是有用的
	- K 是很关键的
	- 不同的K最后学到的稀疏性如何
- 引入 minp，进行对比实验
	- 对齐，我们的 train 用来训练 theta，minp 的train set 用来学超参数
	- 能够improve的主要就是data adaptive