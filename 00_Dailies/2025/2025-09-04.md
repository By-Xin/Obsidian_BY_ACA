# 每次推理时
input_sequence = "the capital of France is"
logits = base_model(input_sequence)  # (1, vocab_size)
probs = softmax(logits)              # (1, vocab_size)
truncated_probs = minp_head(probs)   # (1, vocab_size) - 截断后的概率
next_token = sample(truncated_probs) # 采样得到下一个token
