
## ðŸš€ å¿«é€Ÿå¼€å§‹

### è¿žæŽ¥æ–¹å¼

**SSH ç™»å½•ï¼ˆæŽ¨èæ—¥å¸¸ä½¿ç”¨ï¼‰**

```bash
ssh sczd425@BSCC-N16R4@ssh.cn-zhongwei-1.paracloud.com -p 22
```

- å¯†ç ï¼š`VCCvcc123,.`

**ç½‘é¡µç‰ˆç™»å½•ï¼ˆé€‚åˆæ–‡ä»¶ç®¡ç†ï¼‰**

- ç½‘å€ï¼šhttps://cloud.blsc.cn/
- ç”¨æˆ·åï¼š`jianqw@mail.tsinghua.edu.cn`
- å¯†ç ï¼š`ABCDE12345`
- æä¾›è™šæ‹Ÿæ¡Œé¢çŽ¯å¢ƒï¼ŒåŒ…å«æ–‡ä»¶ä¼ è¾“å·¥å…·

## ðŸ’» ç³»ç»Ÿæž¶æž„

### èŠ‚ç‚¹ç±»åž‹

- **ç™»å½•èŠ‚ç‚¹ (ln01)ï¼š** 80 vCPUæ ¸ï¼Œ252GBå†…å­˜
    - âš ï¸ **ä»…ç”¨äºŽç™»å½•ã€æ–‡ä»¶ç®¡ç†ã€ä½œä¸šæäº¤ï¼Œä¸è¦è¿è¡Œè®¡ç®—ä»»åŠ¡**
- **GPUè®¡ç®—èŠ‚ç‚¹ (g0001-gxxxx)ï¼š** æ¯å°é…ç½®8å—NVIDIA RTX4090 24GBæ˜¾å­˜
    - æ¯å—GPUé»˜è®¤åˆ†é…ï¼š8ä¸ªCPUæ ¸ + 126GBå†…å­˜

### å­˜å‚¨ç»“æž„

```
~/                          # å®¶ç›®å½• (1GBé…é¢)
â”œâ”€â”€ .bashrc                 # çŽ¯å¢ƒé…ç½®æ–‡ä»¶
â””â”€â”€ run/                    # å·¥ä½œç›®å½• (300GBé…é¢)
    â”œâ”€â”€ [ä¸ªäººæ–‡ä»¶å¤¹]/        # æ‚¨çš„é¡¹ç›®ç›®å½•
    â”œâ”€â”€ vcc/data/           # VCCåŽŸå§‹æ•°æ®
    â””â”€â”€ process/            # å¤„ç†åŽçš„ä»£ç å’Œæ•°æ®
```

## ðŸ”§ è½¯ä»¶çŽ¯å¢ƒç®¡ç†

### Module ç³»ç»ŸåŸºç¡€

```bash
module avail                # æŸ¥çœ‹æ‰€æœ‰å¯ç”¨è½¯ä»¶
module list                 # æŸ¥çœ‹å½“å‰å·²åŠ è½½çš„è½¯ä»¶
module load [è½¯ä»¶å]        # åŠ è½½è½¯ä»¶çŽ¯å¢ƒ
module unload [è½¯ä»¶å]      # å¸è½½è½¯ä»¶çŽ¯å¢ƒ
module show [è½¯ä»¶å]        # æŸ¥çœ‹è½¯ä»¶è¯¦ç»†ä¿¡æ¯
```

### å·²å®‰è£…è½¯ä»¶åˆ—è¡¨

|è½¯ä»¶|å¯ç”¨ç‰ˆæœ¬|
|---|---|
|miniforge3|24.11|
|gcc|11.4.0, 12.4.0, 13.3.0, 14.2.0|
|CUDA|11.8, 12.1, 12.4|

### Python çŽ¯å¢ƒé…ç½®

**1. åŠ è½½ Miniforge**

```bash
module load miniforge/24.11
```

**2. åˆ›å»º Python çŽ¯å¢ƒ**

```bash
# åˆ›å»º Python 3.7 çŽ¯å¢ƒ
conda create --name py37 python=3.7

# æ¿€æ´»çŽ¯å¢ƒ
source activate py37

# éªŒè¯ç‰ˆæœ¬
python --version
```

**3. å®‰è£… PyTorch ç¤ºä¾‹**

```bash
# CUDA 11.8 ç‰ˆæœ¬
conda install pytorch torchvision torchaudio cudatoolkit=11.8 -c pytorch

# æˆ–ä½¿ç”¨ pip
pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118
```

## ðŸŽ¯ ä½œä¸šæäº¤æŒ‡å—

### ç†è§£ä½œä¸šè°ƒåº¦ç³»ç»Ÿ

**srun vs salloc vs sbatchï¼š**

|å‘½ä»¤|ç”¨é€”|ç‰¹ç‚¹|ä½¿ç”¨åœºæ™¯|
|---|---|---|---|
|`srun`|åŒæ­¥äº¤äº’å¼|å…³é—­ç»ˆç«¯å°±ç»“æŸ|å¿«é€Ÿæµ‹è¯•ã€è°ƒè¯•|
|`salloc`|å¼‚æ­¥äº¤äº’å¼|éœ€è¦æ‰‹åŠ¨å–æ¶ˆä½œä¸š|é•¿æ—¶é—´äº¤äº’å¼å¼€å‘|
|`sbatch`|æ‰¹é‡æäº¤|åŽå°è¿è¡Œï¼ŒæŽ¨èä½¿ç”¨|æ­£å¼è®­ç»ƒã€ç”Ÿäº§ä»»åŠ¡|

### æ–¹æ³•1ï¼šå¿«é€Ÿäº¤äº’å¼æµ‹è¯•ï¼ˆsrunï¼‰

**é€‚ç”¨åœºæ™¯ï¼š** è°ƒè¯•ä»£ç ã€å¿«é€ŸéªŒè¯

```bash
# ç”³è¯·1å—GPUï¼Œ2å°æ—¶æ—¶é™
srun -p gpu --gpus=1 --time=2:00:00 --pty /bin/bash

# çŽ°åœ¨æ‚¨åœ¨GPUèŠ‚ç‚¹ä¸Šï¼Œå¯ä»¥ç›´æŽ¥è¿è¡Œ
module load miniforge/24.11
source activate py37
python your_script.py
```

### æ–¹æ³•2ï¼šæ‰¹é‡ä½œä¸šæäº¤ï¼ˆsbatchï¼ŒæŽ¨èï¼‰

**æ­¥éª¤1ï¼šåˆ›å»ºä½œä¸šè„šæœ¬**

```bash
# åˆ›å»º run.sh æ–‡ä»¶
nano run.sh
```

**æ­¥éª¤2ï¼šç¼–å†™ä½œä¸šè„šæœ¬å†…å®¹**

```bash
#!/bin/bash
#SBATCH -p gpu                    # ä½¿ç”¨GPUé˜Ÿåˆ—
#SBATCH --gpus=1                  # ç”³è¯·1å—GPU
#SBATCH --time=04:00:00           # æœ€é•¿è¿è¡Œ4å°æ—¶
#SBATCH --job-name=my_training    # ä½œä¸šåç§°
#SBATCH --output=output_%j.log    # è¾“å‡ºæ–‡ä»¶ï¼ˆ%jæ˜¯ä½œä¸šIDï¼‰

# åŠ è½½è½¯ä»¶çŽ¯å¢ƒ
module load miniforge/24.11
module load cuda/11.8

# æ¿€æ´»PythonçŽ¯å¢ƒ
source activate py37

# è¿è¡Œæ‚¨çš„ç¨‹åº
python train.py
```

**æ­¥éª¤3ï¼šæäº¤ä½œä¸š**

```bash
chmod +x run.sh              # ç»™è„šæœ¬æ‰§è¡Œæƒé™
sbatch run.sh                # æäº¤ä½œä¸š
```

### æ–¹æ³•3ï¼šç›´æŽ¥è¿è¡Œå·²æœ‰è„šæœ¬

**å¦‚æžœæ‚¨å·²æœ‰ shell è„šæœ¬ï¼š**

```bash
# ç›´æŽ¥æäº¤shæ–‡ä»¶
sbatch -p gpu --gpus=1 --time=2:00:00 your_script.sh
```

**å¦‚æžœæ‚¨è¦ç›´æŽ¥è¿è¡ŒPythonæ–‡ä»¶ï¼š**

```bash
# æ–¹å¼1ï¼šä¸€è¡Œå‘½ä»¤
srun -p gpu --gpus=1 --time=1:00:00 python your_script.py

# æ–¹å¼2ï¼šåˆ›å»ºç®€å•è„šæœ¬
echo '#!/bin/bash
module load miniforge/24.11
python your_script.py' > quick_run.sh

sbatch -p gpu --gpus=1 quick_run.sh
```

## ðŸ“Š ä½œä¸šç®¡ç†

### æŸ¥çœ‹ä½œä¸šçŠ¶æ€

```bash
parajobs                     # æŸ¥çœ‹æ‚¨æäº¤çš„æ‰€æœ‰ä½œä¸š
```

è¾“å‡ºç¤ºä¾‹ï¼š

```
JOBID  PARTITION  NAME     USER  ST  TIME   NODES  NODELIST(REASON)
26     gpu        run.sh   æ‚¨çš„ç”¨æˆ·å  R   1:52   1      g0001
```

### å–æ¶ˆä½œä¸š

```bash
scancel 26                   # å–æ¶ˆä½œä¸šIDä¸º26çš„ä½œä¸š
```

### æŸ¥çœ‹ä½œä¸šè¾“å‡º

```bash
# ä½œä¸šè¿è¡Œæ—¶çš„è¾“å‡ºé»˜è®¤ä¿å­˜åœ¨ï¼š
tail -f slurm-ä½œä¸šID.out      # å®žæ—¶æŸ¥çœ‹è¾“å‡º
cat slurm-26.out            # æŸ¥çœ‹å®Œæ•´è¾“å‡º
```

## ðŸ”¥ å¸¸è§ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šæ·±åº¦å­¦ä¹ è®­ç»ƒ

```bash
# run_training.sh
#!/bin/bash
#SBATCH -p gpu --gpus=1 --time=12:00:00

module load miniforge/24.11
module load cuda/11.8
source activate pytorch_env

python train.py --epochs 100 --batch_size 32
```

### åœºæ™¯2ï¼šå¤šGPUå¹¶è¡Œè®­ç»ƒ

```bash
# multi_gpu.sh
#!/bin/bash
#SBATCH -p gpu --gpus=4 --time=8:00:00

module load miniforge/24.11
module load cuda/11.8
source activate pytorch_env

# 4å¡å¹¶è¡Œè®­ç»ƒ
python -m torch.distributed.launch --nproc_per_node=4 train.py
```

### åœºæ™¯3ï¼šè·¨èŠ‚ç‚¹å¤§è§„æ¨¡è®­ç»ƒ

```bash
# cluster_training.sh
#!/bin/bash
#SBATCH -N 2 -p gpu --gres=gpu:8 --ntasks-per-node=8 --qos=gpugpu

module load miniforge/24.11
module load cuda/11.8
export NCCL_DEBUG=INFO

# 16å¡è·¨èŠ‚ç‚¹è®­ç»ƒ
python -m torch.distributed.launch --nnodes=2 --node_rank=$SLURM_NODEID train.py
```

## âš¡ é«˜çº§åŠŸèƒ½

### å†…å­˜æ–‡ä»¶ç³»ç»Ÿï¼ˆé«˜é€ŸIOï¼‰

```bash
# åœ¨è„šæœ¬ä¸­å°†æ•°æ®è§£åŽ‹åˆ°å†…å­˜
tar -xf datasets.tar -C /dev/shm/
# ç„¶åŽåœ¨Pythonä¸­è¯»å– /dev/shm/datasets/ çš„æ•°æ®
```

### VIPé˜Ÿåˆ—ï¼ˆå¦‚æžœæ‚¨æœ‰åŒ…èŠ‚ç‚¹æƒé™ï¼‰

```bash
sbatch --gpus=8 -p vip_gpu_ç”¨æˆ·å ./run.sh
```

## ðŸ› ï¸ å®žç”¨æŠ€å·§

### çŽ¯å¢ƒæŒä¹…åŒ–

```bash
# å°†å¸¸ç”¨moduleå†™å…¥é…ç½®æ–‡ä»¶
echo "module load miniforge/24.11" >> ~/.bashrc
echo "module load cuda/11.8" >> ~/.bashrc
```

### ç›‘æŽ§GPUä½¿ç”¨

```bash
# åœ¨GPUèŠ‚ç‚¹ä¸ŠæŸ¥çœ‹GPUçŠ¶æ€
nvidia-smi

# åœ¨Pythonä¸­ç›‘æŽ§
import torch
print(f"GPUå¯ç”¨: {torch.cuda.is_available()}")
print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
```

### æ•°æ®ä¼ è¾“

```bash
# ä½¿ç”¨scpä¸Šä¼ æ–‡ä»¶
scp local_file.py sczd425@BSCC-N16R4@ssh.cn-zhongwei-1.paracloud.com:~/run/

# æˆ–ä½¿ç”¨ç½‘é¡µç‰ˆçš„è™šæ‹Ÿæ¡Œé¢è¿›è¡Œæ‹–æ‹½ä¸Šä¼ 
```

## ðŸ“ å®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹

```bash
# 1. ç™»å½•ç³»ç»Ÿ
ssh sczd425@BSCC-N16R4@ssh.cn-zhongwei-1.paracloud.com -p 22

# 2. åˆ›å»ºå·¥ä½œç›®å½•
mkdir -p ~/run/my_project
cd ~/run/my_project

# 3. ä¸Šä¼ ä»£ç å’Œæ•°æ®
# (ä½¿ç”¨scpæˆ–ç½‘é¡µç‰ˆä¸Šä¼ )

# 4. è®¾ç½®PythonçŽ¯å¢ƒï¼ˆé¦–æ¬¡ï¼‰
module load miniforge/24.11
conda create --name myenv python=3.8
source activate myenv
pip install torch torchvision

# 5. åˆ›å»ºä½œä¸šè„šæœ¬
cat > run_job.sh << 'EOF'
#!/bin/bash
#SBATCH -p gpu
#SBATCH --gpus=1
#SBATCH --time=6:00:00
#SBATCH --job-name=my_experiment

module load miniforge/24.11
module load cuda/11.8
source activate myenv

python train.py
EOF

# 6. æäº¤ä½œä¸š
chmod +x run_job.sh
sbatch run_job.sh

# 7. ç›‘æŽ§ä½œä¸š
parajobs

# 8. æŸ¥çœ‹ç»“æžœ
tail -f slurm-*.out
```

## âš ï¸ é‡è¦æ³¨æ„äº‹é¡¹

1. **ä¸è¦åœ¨ç™»å½•èŠ‚ç‚¹è¿è¡Œè®¡ç®—ä»»åŠ¡** - ä¼šå½±å“æ‰€æœ‰ç”¨æˆ·
2. **ä½¿ç”¨sallocåŽè®°å¾—æ‰‹åŠ¨å–æ¶ˆ** - é¿å…æµªè´¹èµ„æº
3. **æ•°æ®è¶…è¿‡300GBéœ€ç”³è¯·æ‰©å®¹** - è”ç³»ç®¡ç†å‘˜
4. **æ¯ä¸ªä½œä¸šç”³è¯·1-8å¼ GPUå¡** - å•ä½œä¸šä¸è¶…è¿‡8å¡
5. **åˆç†è®¾ç½®æ—¶é—´é™åˆ¶** - é¿å…ä½œä¸šæŽ’é˜Ÿè¿‡ä¹…

## ðŸ†˜ æ•…éšœæŽ’é™¤

### å¸¸è§é—®é¢˜

**Q: æäº¤ä½œä¸šåŽä¸€ç›´PENDINGï¼Ÿ** A: å¯èƒ½æ˜¯èµ„æºä¸è¶³ï¼Œå°è¯•å‡å°‘GPUæ•°é‡æˆ–ç­‰å¾…

**Q: Pythonæ‰¾ä¸åˆ°ï¼Ÿ** A: æ£€æŸ¥æ˜¯å¦åŠ è½½äº†miniforge module

**Q: CUDAä¸å¯ç”¨ï¼Ÿ** A: æ£€æŸ¥æ˜¯å¦åŠ è½½äº†æ­£ç¡®ç‰ˆæœ¬çš„CUDA module

**Q: ä½œä¸šçªç„¶ä¸­æ–­ï¼Ÿ** A: æ£€æŸ¥æ—¶é—´é™åˆ¶è®¾ç½®ï¼Œå¯èƒ½è¶…æ—¶è¢«ç³»ç»Ÿæ€æŽ‰

### èŽ·å–å¸®åŠ©

- æŠ€æœ¯æ”¯æŒï¼šè”ç³»é›†ç¾¤ç®¡ç†å‘˜
- å¾®ä¿¡æœåŠ¡ç¾¤ï¼š@å®¢æœï¼ˆå¦‚æ–‡æ¡£ä¸­æåˆ°ï¼‰

## ðŸ“š å‚è€ƒèµ„æº

- ç™»å½•èŠ‚ç‚¹ä»…ç”¨äºŽä½œä¸šæäº¤å’Œæ–‡ä»¶ç®¡ç†
- è®¡ç®—ä»»åŠ¡å¿…é¡»é€šè¿‡ä½œä¸šè°ƒåº¦ç³»ç»Ÿè¿è¡Œ
- åˆç†ä½¿ç”¨èµ„æºï¼Œéµå¾ªé›†ç¾¤ä½¿ç”¨è§„èŒƒ

---

**è®°ä½ï¼šç™»å½• â†’ åŠ è½½çŽ¯å¢ƒ â†’ æäº¤ä½œä¸š â†’ ç›‘æŽ§çŠ¶æ€ â†’ æŸ¥çœ‹ç»“æžœ**